{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":658267,"sourceType":"datasetVersion","datasetId":277323}],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-06T09:03:58.857195Z","iopub.execute_input":"2025-11-06T09:03:58.857570Z","iopub.status.idle":"2025-11-06T09:04:00.640522Z","shell.execute_reply.started":"2025-11-06T09:03:58.857544Z","shell.execute_reply":"2025-11-06T09:04:00.639702Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nfrom glob import glob\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\n\n\nDATA_DIR = \"/kaggle/input/plantvillage-dataset\"  # Change if path differs\n\nMODALITIES = [\"color\", \"grayscale\", \"segmented\"]\nIMAGE_SIZE = 224  # Standard for pretrained models\n\n\nclass MultiModalityDataset(Dataset):\n    def __init__(self, samples, modality_transforms):\n        \"\"\"\n        samples: list of (img_path, label_id, modality_name)\n        modality_transforms: dict {modality_name: transform}\n        \"\"\"\n        self.samples = samples\n        self.transforms = modality_transforms\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        img_path, label, modality = self.samples[idx]\n\n        img = Image.open(img_path).convert(\"RGB\")  # Convert all to RGB\n        img = self.transforms[modality](img)\n\n        return {\n            \"image\": img,\n            \"label\": torch.tensor(label, dtype=torch.long),\n            \"modality\": modality\n        }\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:19:42.018810Z","iopub.execute_input":"2025-10-28T15:19:42.019190Z","iopub.status.idle":"2025-10-28T15:20:22.233551Z","shell.execute_reply.started":"2025-10-28T15:19:42.019166Z","shell.execute_reply":"2025-10-28T15:20:22.232574Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1Ô∏è‚É£ Build class name ‚Üí ID mapping\nclass_names = sorted(next(os.walk(os.path.join(DATA_DIR, \"color\")))[1])\nclass_to_idx = {cls: i for i, cls in enumerate(class_names)}\n\n# 2Ô∏è‚É£ Gather all samples (paths + labels + modality)\nsamples = []\nfor modality in MODALITIES:\n    for cls in class_names:\n        folder = os.path.join(DATA_DIR, modality, cls)\n        for img_path in glob(os.path.join(folder, \"*.jpg\")):\n            samples.append((img_path, class_to_idx[cls], modality))\n\nprint(f\"Total samples found: {len(samples)}\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3Ô∏è‚É£ Train/Val/Test split\ntrain_val, test = train_test_split(samples, test_size=0.15, shuffle=True, stratify=[s[1] for s in samples])\ntrain, val = train_test_split(train_val, test_size=0.18, shuffle=True, stratify=[s[1] for s in train_val])\n# Final: ~70% train / 15% val / 15% test\n\nprint(f\"Train: {len(train)}, Val: {len(val)}, Test: {len(test)}\")\n\n\ndef get_transforms(train=True):\n    if train:\n        return {\n            \"color\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomRotation(10),\n                transforms.ColorJitter(0.2,0.2),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225]),\n            ]),\n            \"grayscale\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.RandomHorizontalFlip(),\n                transforms.RandomRotation(10),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                     std=[0.5, 0.5, 0.5])\n            ]),\n            \"segmented\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.RandomHorizontalFlip(),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                     std=[0.5, 0.5, 0.5])\n            ]),\n        }\n    else:\n        return {\n            \"color\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225]),\n            ]),\n            \"grayscale\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                     std=[0.5, 0.5, 0.5])\n            ]),\n            \"segmented\": transforms.Compose([\n                transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n                transforms.ToTensor(),\n                transforms.Normalize(mean=[0.5, 0.5, 0.5],\n                                     std=[0.5, 0.5, 0.5])\n            ]),\n        }\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5Ô∏è‚É£ Build datasets\ntrain_dataset = MultiModalityDataset(train, get_transforms(train=True))\nval_dataset   = MultiModalityDataset(val, get_transforms(train=False))\ntest_dataset  = MultiModalityDataset(test, get_transforms(train=False))\n\n\n# 6Ô∏è‚É£ DataLoaders\nBATCH_SIZE = 32\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\nval_loader   = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\ntest_loader  = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n\n\nprint(\"‚úÖ DataLoaders are ready!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def make_subset(samples, ratio, seed=42):\n    subset, _ = train_test_split(\n        samples,\n        train_size=ratio,\n        stratify=[s[1] for s in samples],\n        random_state=seed\n    )\n    return subset\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Small subset for quick testing\ntrain_tiny = make_subset(train, 0.05)\ntrain_tiny_dataset = MultiModalityDataset(train_tiny, get_transforms(train=True))\ntrain_tiny_loader = DataLoader(train_tiny_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n\n# Medium subset for hyperparameter tuning\ntrain_medium = make_subset(train, 0.3)\ntrain_medium_dataset = MultiModalityDataset(train_medium, get_transforms(train=True))\ntrain_medium_loader = DataLoader(train_medium_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision.models import vit_b_16, ViT_B_16_Weights\nfrom torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\nimport copy\nimport os\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n\n# 1Ô∏è‚É£ Load pretrained ViT\nweights = ViT_B_16_Weights.IMAGENET1K_V1\nmodel = vit_b_16(weights=weights)\n\n\n# 2Ô∏è‚É£ Freeze feature layers (freeze everything except head)\nfor param in model.parameters():\n    param.requires_grad = False\n\n\n# 3Ô∏è‚É£ Replace the classification head\nnum_classes = len(class_names)  # from previous cell\nmodel.heads = nn.Sequential(\n    nn.Linear(model.heads.head.in_features, 512),\n    nn.ReLU(),\n    nn.Dropout(0.3),\n    nn.Linear(512, num_classes)\n)\n\nmodel.to(device)\n\n\n# 4Ô∏è‚É£ Define Loss & Optimizer (only head parameters train)\ncriterion = nn.CrossEntropyLoss()\noptimizer = Adam(model.heads.parameters(), lr=1e-4)\nscheduler = StepLR(optimizer, step_size=3, gamma=0.1)\n\n\n# 5Ô∏è‚É£ Training + Validation Loop\nSAVE_PATH = \"best_vit_model.pth\"  # Saved in working directory\n\n\ndef train_model(num_epochs=1000, patience=100):\n    best_val_loss = float(\"inf\")\n    best_model_wts = copy.deepcopy(model.state_dict())\n    no_improve_epochs = 0\n\n    for epoch in range(num_epochs):\n        # ---------- Training ----------\n        model.train()\n        train_loss = 0.0\n        train_correct = 0\n        train_total = 0\n\n        for batch in train_loader:\n            images = batch[\"image\"].to(device)\n            labels = batch[\"label\"].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            train_loss += loss.item() * images.size(0)\n            _, predicted = outputs.max(1)\n            train_correct += predicted.eq(labels).sum().item()\n            train_total += labels.size(0)\n\n        train_loss /= train_total\n        train_acc = train_correct / train_total\n\n        # ---------- Validation ----------\n        model.eval()\n        val_loss = 0.0\n        val_correct = 0\n        val_total = 0\n\n        with torch.no_grad():\n            for batch in val_loader:\n                images = batch[\"image\"].to(device)\n                labels = batch[\"label\"].to(device)\n\n                outputs = model(images)\n                loss = criterion(outputs, labels)\n\n                val_loss += loss.item() * images.size(0)\n                _, predicted = outputs.max(1)\n                val_correct += predicted.eq(labels).sum().item()\n                val_total += labels.size(0)\n\n        val_loss /= val_total\n        val_acc = val_correct / val_total\n\n        # ---------- Scheduler step ----------\n        scheduler.step()\n\n        # ---------- Best model save ----------\n        if val_loss < best_val_loss:\n            best_val_loss = val_loss\n            best_model_wts = copy.deepcopy(model.state_dict())\n            torch.save(best_model_wts, SAVE_PATH)\n            no_improve_epochs = 0\n            improved = \"‚úÖ (improved & saved)\"\n        else:\n            no_improve_epochs += 1\n            improved = \"\"\n\n        print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n              f\"| Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} \"\n              f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} \"\n              + improved)\n\n        # ---------- Optional Early Stopping ----------\n        if patience is not None and no_improve_epochs >= patience:\n            print(f\"‚èπ Early stopping at epoch {epoch+1} ‚Äî no improvement for {patience} epochs.\")\n            break\n\n    print(\"üèÅ Training finished!\")\n\n    # Load best weights before returning\n    model.load_state_dict(best_model_wts)\n    return model\n\n\nmodel = train_model(num_epochs=1000, patience=100)\nprint(\"‚úÖ Best model restored & ready!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-28T15:20:22.234321Z","iopub.execute_input":"2025-10-28T15:20:22.234699Z","execution_failed":"2025-10-28T16:18:13.359Z"}},"outputs":[],"execution_count":null}]}